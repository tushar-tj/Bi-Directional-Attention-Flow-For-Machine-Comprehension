{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tusjoshi/Desktop/practice_projects/venv/lib/python3.7/site-packages/ipykernel_launcher.py:26: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.parse.corenlp.CoreNLPParser\u001b[0m instead.'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import sys\n",
    "import re\n",
    "import torch\n",
    "import datetime\n",
    "import torchtext\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from collections import Counter\n",
    "from torchtext.vocab import GloVe\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "from nltk.tokenize.stanford import StanfordTokenizer\n",
    "\n",
    "np.random.seed(15)\n",
    "nltk_tokenizer = TreebankWordTokenizer()\n",
    "ptb_tokenizer = StanfordTokenizer('../../../../data/stanford-parser-full-2018-02-27/stanford-parser.jar')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_ptbtokenizer(text):\n",
    "    return text.split(' ')\n",
    "\n",
    "def ptbtokenizer(text, context=False):\n",
    "    text = text.replace('’', \"'\")\n",
    "    text = text.replace(\"..\", \".\")\n",
    "    text = text.replace(\". .\", \".\")\n",
    "    text = text.replace(\"´\", \"'\")\n",
    "    text = text.replace(\"`\", \"'\")\n",
    "    doc = ptb_tokenizer.tokenize(text)\n",
    "    \n",
    "    output = []\n",
    "    for token in doc:\n",
    "        _token = re.split('([$.])', token)\n",
    "        _token = [i for i in _token if len(i)>0]\n",
    "        output = output + _token\n",
    "    \n",
    "    if context:\n",
    "        output.append('<eoc>')\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_checkpoint_paths(folder_path):\n",
    "    if not os.path.isdir(folder_path):\n",
    "        os.mkdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadData():\n",
    "    def __init__(self, \n",
    "                 data_path, \n",
    "                 checkpoint_path):\n",
    "        self.data_path = data_path\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.train_data = self.load_train_data()\n",
    "        self.dev_data = self.load_dev_data()   \n",
    "        \n",
    "    def load_train_data(self):\n",
    "        with open(self.data_path + 'train-v1.1.json', 'r') as f:\n",
    "            train_data = json.load(f)\n",
    "        print (f'\\nFlattening SQUAD {train_data[\"version\"]} - Train')\n",
    "        train_data_flat, errors = self.load_squad_data(train_data)\n",
    "        print (f'\\nErronous Train Datapoints: {errors}')\n",
    "        pd.DataFrame(train_data_flat).to_csv(self.checkpoint_path + 'train.csv', encoding='utf-8')\n",
    "        \n",
    "    def load_dev_data(self):\n",
    "        with open(self.data_path + 'dev-v1.1.json', 'r') as f:\n",
    "            dev_data = json.load(f)\n",
    "        print (f'\\nFlattening SQUAD Dev')\n",
    "        dev_data_flat, errors = self.load_squad_data(dev_data)\n",
    "        print (f'\\nErronous Dev Datapoints: {errors}')\n",
    "        pd.DataFrame(dev_data_flat).to_csv(self.checkpoint_path + 'dev.csv', encoding='utf-8')       \n",
    "    \n",
    "    def convert_charidx_to_wordidx(self, context_tok, ans_tok):                               \n",
    "        length = len(ans_tok)\n",
    "        _start, _end = None, None\n",
    "        \n",
    "        for i in range(len(context_tok)):\n",
    "            context_text = \" \".join(context_tok[i:i+length]).strip('.')\n",
    "            ans_text = \" \".join(ans_tok).strip('.')\n",
    "            _ans_text = \"\".join(ans_tok).strip('.')\n",
    "            __ans_text = \" \".join(ans_tok).strip(',')\n",
    "            \n",
    "            if ans_text in context_text or _ans_text in context_text or __ans_text in context_text:\n",
    "                _start = i\n",
    "                _end = i+length\n",
    "                break\n",
    "          \n",
    "        if _start == None:\n",
    "            for i in range(len(context_tok)):\n",
    "                if ans_tok[0] == context_tok[i]:\n",
    "                    _start = i\n",
    "                    _end = i+length\n",
    "                    \n",
    "        if _start == None:\n",
    "            print (ans_tok)\n",
    "            print (context_tok)\n",
    "        \n",
    "        if _end != None and _end >= len(context_tok):\n",
    "            _end = len(context_tok) - 1\n",
    "            \n",
    "        return _start, _end\n",
    "        \n",
    "    def load_squad_data(self, data):\n",
    "        progress = 0\n",
    "        errors = 0\n",
    "        start_time = time.time()\n",
    "        flatened_data = []\n",
    "        for topics in data['data']:\n",
    "            title = topics['title']\n",
    "            for paragraphs in topics['paragraphs']:\n",
    "                context = paragraphs['context']\n",
    "#                 context_tok = ptbtokenizer(context, context=True)\n",
    "                for qas in paragraphs['qas']:\n",
    "                    id = qas['id']\n",
    "                    question = qas['question']\n",
    "                    for answer in qas['answers']:\n",
    "                        progress += 1\n",
    "                        \n",
    "                        time_delta = datetime.timedelta(seconds=np.round(time.time() - start_time, 0))\n",
    "                        sys.stdout.write(f'\\rCompleted: {progress} | Time: {time_delta}')\n",
    "                        if progress > 2000:\n",
    "                            continue\n",
    "                        context_tok = ptbtokenizer(context, context=True)\n",
    "                        \n",
    "                        answer_start = answer['answer_start']\n",
    "                        answer_end = answer['answer_start'] + len(answer['text'])\n",
    "                        \n",
    "                        ans_tok = ptbtokenizer(context[answer_start:answer_end])\n",
    "                        question_tok = ptbtokenizer(question)\n",
    "                        \n",
    "                        _start, _end = self.convert_charidx_to_wordidx(context_tok, ans_tok)\n",
    "                        if _start == None:\n",
    "                            errors += 1\n",
    "                            continue\n",
    "                        flatened_data.append({'id': id,\n",
    "                                              'context': context,\n",
    "                                              'context_ptb_tok': ' '.join(context_tok),\n",
    "                                              'question': question,\n",
    "                                              'question_ptb_tok': ' '.join(question_tok),\n",
    "                                              'answer_ptb_tok': ' '.join(ans_tok),\n",
    "                                              'start_idx': _start,\n",
    "                                              'end_idx': _end})\n",
    "        \n",
    "        return flatened_data, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessData:\n",
    "    def __init__(self, \n",
    "                 data_path, \n",
    "                 glove_size,\n",
    "                 batch_size):\n",
    "        device = torch.device(\"cuda:{}\".format(args.gpu) if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Defining the Fields\n",
    "        self.RAW = data.RawField(is_target=False)\n",
    "        self.WORDS = data.Field(batch_first=True, \n",
    "                           tokenize=post_ptbtokenizer, \n",
    "                           lower=True, \n",
    "                           include_lengths=True)\n",
    "        self.CHAR = data.NestedField(data.Field(batch_first=True, \n",
    "                                           tokenize=list, \n",
    "                                           lower=True), \n",
    "                                tokenize=post_ptbtokenizer)\n",
    "        \n",
    "        self.INDEX = data.Field(sequential=False, \n",
    "                                unk_token=None, \n",
    "                                use_vocab=False)\n",
    "        \n",
    "        fields = {\n",
    "            'id': ('id', self.RAW),\n",
    "            'context_ptb_tok': [('context_words', self.WORDS), ('context_char', self.CHAR)],\n",
    "            'question_ptb_tok': [('question_words', self.WORDS), ('question_char', self.CHAR)],\n",
    "            'answer_ptb_tok': [('answer_words', self.WORDS), ('answer_char', self.CHAR)],\n",
    "            'start_idx': ('start_idx', self.INDEX),\n",
    "            'end_idx': ('end_idx', self.INDEX)\n",
    "        }\n",
    "\n",
    "\n",
    "        print ('Loading CSV Data Into Torch Tabular Dataset')\n",
    "        self.train, self.dev = data.TabularDataset.splits(\n",
    "            path=data_path,\n",
    "            train='train.csv',\n",
    "            validation = 'dev.csv',\n",
    "            format='csv',\n",
    "            fields=fields)\n",
    "          \n",
    "        print ('Building Vocabulary')\n",
    "        self.CHAR.build_vocab(self.train, self.dev)\n",
    "        self.WORDS.build_vocab(self.train, self.dev, vectors=GloVe(name='6B', dim=glove_size))\n",
    "\n",
    "        print ('Creating Iterators')\n",
    "        self.train_iter = PreprocessData.create_train_iterator(self.train, device, batch_size)\n",
    "        self.dev_iter = PreprocessData.create_dev_iterator(self.dev, device, batch_size)\n",
    "                    \n",
    "            \n",
    "    @staticmethod\n",
    "    def create_train_iterator(train, device, batch_size):\n",
    "        train_iter = data.BucketIterator(\n",
    "            train,\n",
    "            batch_size=batch_size,\n",
    "            device=device,\n",
    "            repeat=False,\n",
    "            shuffle=True,\n",
    "            sort_within_batch=True,\n",
    "            sort_key=lambda x: len(x.context_words))\n",
    "        \n",
    "        return train_iter\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_dev_iterator(dev, device, batch_size):\n",
    "        dev_iter = data.BucketIterator(\n",
    "            dev,\n",
    "            batch_size = batch_size,\n",
    "            device=device,\n",
    "            repeat=False,\n",
    "            sort_within_batch=True,\n",
    "            sort_key=lambda x: len(x.context_words))\n",
    "        \n",
    "        return dev_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_checkpoint_paths('./data_checkpoints/')\n",
    "create_checkpoint_paths('./model_checkpoints/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Flattening SQUAD 1.1 - Train\n",
      "Completed: 87599 | Time: 0:25:09\n",
      "Erronous Train Datapoints: 0\n",
      "\n",
      "Flattening SQUAD Dev\n",
      "Completed: 34726 | Time: 0:23:36\n",
      "Erronous Dev Datapoints: 0\n"
     ]
    }
   ],
   "source": [
    "_ = LoadData(data_path='../../../../data/squad v1.1/', checkpoint_path='./data_checkpoints/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV Data Into Torch Tabular Dataset\n",
      "Building Vocabulary\n",
      "Creating Iterators\n"
     ]
    }
   ],
   "source": [
    "data_preprocessor = PreprocessData(data_path = './data_checkpoints/',\n",
    "                                   glove_size = 100,\n",
    "                                   batch_size = 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BidaF(nn.Module):\n",
    "    def __init__(self, \n",
    "                 WORDS, \n",
    "                 CHAR,\n",
    "                 char_embedding_size, # each character is represented by\n",
    "                 char_conv_kernel_size, # width of convolution layer kernel\n",
    "                 char_conv_channels_count, # no. of convolution layer channels\n",
    "                 dropout=0.2,\n",
    "                ): #\n",
    "        super(BidaF, self).__init__()\n",
    "        self.embedding_size = WORDS.vocab.vectors.shape[1] + char_conv_channels_count\n",
    "        \n",
    "        # 1. Word Embeddings\n",
    "        self.word_embedding_layer = nn.Embedding.from_pretrained(WORDS.vocab.vectors, freeze=True)\n",
    "        \n",
    "        # 2. Char Embeddings\n",
    "        self.char_embedding_layer = nn.Embedding(len(CHAR.vocab), char_embedding_size)\n",
    "        self.convolution_layer = nn.Conv2d(1, char_conv_channels_count, (char_conv_kernel_size, char_embedding_size))\n",
    "        nn.init.xavier_uniform_(self.convolution_layer.weight)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # 3. Highway Network\n",
    "        self.highway_linear1 = nn.Sequential(nn.Linear(self.embedding_size, self.embedding_size), nn.ReLU())\n",
    "        self.highway_gate1 = nn.Sequential(nn.Linear(self.embedding_size, self.embedding_size), nn.Sigmoid())\n",
    "        \n",
    "        self.highway_linear2 = nn.Sequential(nn.Linear(self.embedding_size, self.embedding_size), nn.ReLU())\n",
    "        self.highway_gate2 = nn.Sequential(nn.Linear(self.embedding_size, self.embedding_size), nn.Sigmoid())\n",
    "        \n",
    "        # 4. Embedding LSTM Layer\n",
    "        self.embed_LSTM = nn.LSTM(input_size=self.embedding_size, \n",
    "                                  hidden_size=self.embedding_size, \n",
    "                                  num_layers=1,\n",
    "                                  batch_first=True, \n",
    "                                  bidirectional=True)\n",
    "        nn.init.xavier_normal_(self.embed_LSTM.weight_hh_l0)\n",
    "        nn.init.xavier_normal_(self.embed_LSTM.weight_ih_l0)\n",
    "        \n",
    "        # 5. Attention Flow Layer\n",
    "        self.w = torch.empty((6*self.embedding_size, 1), device=device)\n",
    "        nn.init.xavier_normal_(self.w)\n",
    "        \n",
    "        # 6. Modelling Layer\n",
    "        self.modelling_LSTM1 = nn.LSTM(input_size=8*self.embedding_size, \n",
    "                                       hidden_size=self.embedding_size,\n",
    "                                       num_layers=1,\n",
    "                                       batch_first=True,\n",
    "                                       bidirectional=True)\n",
    "        nn.init.xavier_normal_(self.modelling_LSTM1.weight_hh_l0)\n",
    "        nn.init.xavier_normal_(self.modelling_LSTM1.weight_ih_l0)\n",
    "        \n",
    "        self.modelling_LSTM2 = nn.LSTM(input_size=2*self.embedding_size, \n",
    "                                       hidden_size=self.embedding_size,\n",
    "                                       num_layers=1,\n",
    "                                       batch_first=True,\n",
    "                                       bidirectional=True)\n",
    "        nn.init.xavier_normal_(self.modelling_LSTM2.weight_hh_l0)\n",
    "        nn.init.xavier_normal_(self.modelling_LSTM2.weight_ih_l0)\n",
    "        \n",
    "        # 7. Output Layer\n",
    "        self.p1_w = nn.Linear(10 * self.embedding_size, 1)\n",
    "        nn.init.xavier_normal_(self.p1_w.weight)\n",
    "        \n",
    "        self.p2_w = nn.Linear(10 * self.embedding_size, 1)\n",
    "        nn.init.xavier_normal_(self.p2_w.weight)\n",
    "        \n",
    "    def word_embeddings(self, x):\n",
    "        x = self.word_embedding_layer(x)\n",
    "        return x\n",
    "    \n",
    "    def character_embeddings(self, x):\n",
    "        x = self.char_embedding_layer(x) # batch X words X char X char_emb\n",
    "        _s = x.shape\n",
    "        \n",
    "        # Reshaping vector as we wish to run the character level embedding over each word in the batch\n",
    "        x = x.view(_s[0]*_s[1], 1, _s[2], _s[3])  \n",
    "        x = self.convolution_layer(x)\n",
    "        x = nn.functional.relu(x).squeeze(3)\n",
    "        x = nn.functional.max_pool1d(x, x.shape[2]).squeeze(2)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Shaping back to original batch_size, max_count_of_word_in_batch, char_conv_channels_count\n",
    "        x = x.view(_s[0], _s[1], -1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    \n",
    "    def highway_network(self, x1, x2):\n",
    "        x = torch.cat([x1, x2], -1)\n",
    "        \n",
    "        x = self.highway_linear1(x)\n",
    "        t1 = self.highway_gate1(x)\n",
    "        \n",
    "        x = t1 * x + (1 - t1) * x\n",
    "        \n",
    "        x = self.highway_linear2(x)\n",
    "        t2 = self.highway_gate2(x)\n",
    "        \n",
    "        x = t2 * x + (1 - t2) * x\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def lstm_embedding(self, x, x_lengths):\n",
    "        x = torch.nn.utils.rnn.pack_padded_sequence(x, x_lengths, enforce_sorted=False, batch_first=True)\n",
    "        x, _ = self.embed_LSTM(x)\n",
    "        x, _ = torch.nn.utils.rnn.pad_packed_sequence(x, batch_first=True)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def attention_flow_layer(self, c, q, c_len, q_len, batch_size):\n",
    "        # Calculate the similarity matrix\n",
    "        S = torch.empty((batch_size, c_len, q_len), device=device)\n",
    "        for t in range(c_len):\n",
    "            for j in range(q_len):\n",
    "                _x = torch.cat([c[:, t, :], q[:, j, :], c[:, t, :] * q[:, j, :]], dim=-1)\n",
    "                S[:, t, j] = torch.mm(_x, self.w).squeeze(1)\n",
    "                \n",
    "        # Calculating Context to Query Attention Matrix\n",
    "        c2q_attn = torch.empty((batch_size, c_len, 2*self.embedding_size), device=device)\n",
    "        A = F.softmax(S, dim=1)\n",
    "        for t in range(c_len):\n",
    "            c2q_attn[:, t, :] = (S[:, t, :].unsqueeze(2) * q).sum(1)\n",
    "        \n",
    "        # Calculating Query to Context Attention Matrix\n",
    "        z, _ = torch.max(S ,dim=2)\n",
    "        b = F.softmax(z, dim=1).unsqueeze(2)\n",
    "        _h = (b * c2q_attn).sum(1).unsqueeze(1)\n",
    "        q2c_attn = _h.repeat(1, c_len, 1)\n",
    "        \n",
    "        # Merging all Information\n",
    "        G = torch.cat([c, c2q_attn, c * c2q_attn, c * q2c_attn], dim=-1)\n",
    "        \n",
    "        return G\n",
    "    \n",
    "    def modelling_layer(self, x):\n",
    "        m1, _ = self.modelling_LSTM1(x)\n",
    "        m1 = self.dropout(m1)\n",
    "        \n",
    "        m2, _ = self.modelling_LSTM2(m1)\n",
    "        m2 = self.dropout(m2)\n",
    "        \n",
    "        return m1, m2\n",
    "    \n",
    "    def output_layer(self, G, m1, m2):\n",
    "        \n",
    "        p1 = self.p1_w(torch.cat([G, m1], dim=-1)).squeeze(2)\n",
    "        p2 = self.p2_w(torch.cat([G, m2], dim=-1)).squeeze(2)\n",
    "        return p1, p2\n",
    "    \n",
    "    def mask_output(self, p1, p2):  \n",
    "        # This function replaced the pads with zeros to remove them from loss calculations\n",
    "        max_size = p1.shape[1]\n",
    "        mask = torch.tensor([[1.0] * lengths.item() + [0.0] * (max_size - lengths.item()) \n",
    "                             for lengths in train_data.context_words[1]])\n",
    "        \n",
    "        return mask * p1, mask * p2\n",
    "        \n",
    "    def forward(self, data):\n",
    "        context_word_emb = self.word_embeddings(data.context_words[0])\n",
    "        ques_word_emb = self.word_embeddings(data.question_words[0])\n",
    "                                               \n",
    "        context_char_emb = self.character_embeddings(data.context_char)\n",
    "        ques_char_emb = self.character_embeddings(data.question_char)\n",
    "        \n",
    "        context_emb = self.highway_network(context_word_emb, context_char_emb)\n",
    "        ques_emb = self.highway_network(ques_word_emb, ques_char_emb)\n",
    "        \n",
    "        context_emb = self.lstm_embedding(context_emb, data.context_words[1])\n",
    "        ques_emb = self.lstm_embedding(ques_emb, data.question_words[1])\n",
    "        \n",
    "        G = self.attention_flow_layer(context_emb, ques_emb, \n",
    "                                      data.context_words[1].max().item(), data.question_words[1].max().item(),\n",
    "                                      data.batch_size)\n",
    "        \n",
    "        m1, m2 = self.modelling_layer(G)\n",
    "        p1, p2 = self.output_layer(G, m1, m2)\n",
    "        \n",
    "        # masking output before softmax to remove pads from output calculations\n",
    "        # p1, p2 = self.mask_output(p1, p2)\n",
    "      \n",
    "        p1 = F.softmax(p1, dim=-1)\n",
    "        p2 = F.softmax(p2, dim=-1)\n",
    "        \n",
    "        return p1, p2           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = [i for i in text if i.isalnum() or i.isspace()]\n",
    "    return \"\".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(context, predicted_p1, predicted_p2, actual_p1, actual_p2, method):\n",
    "    acutal_ans =' '.join(context[actual_p1:actual_p2])\n",
    "    predicted_ans = ' '.join(context[predicted_p1:predicted_p2])\n",
    "    acutal_ans = clean_text(acutal_ans)\n",
    "    predicted_ans = clean_text(predicted_ans)\n",
    "#     print (acutal_ans)\n",
    "#     print (predicted_ans)\n",
    "    if method == 'exact_match':  \n",
    "        return 1 if acutal_ans == predicted_ans else 0\n",
    "    else:\n",
    "        pred_tok = predicted_ans.split()\n",
    "        actual_tok = acutal_ans.split()\n",
    "        common = Counter(pred_tok) & Counter(actual_tok)\n",
    "        count_common_words = sum(common.values())\n",
    "        if count_common_words == 0:\n",
    "            return 0.0\n",
    "        precision = 1.0 * count_common_words / len(pred_tok) if len(pred_tok) > 0 else 0.0\n",
    "        recall = 1.0 * count_common_words / len(actual_tok)\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "        return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_batch_accuracy(data, vocab, p1, p2):\n",
    "    p1, p2 = p1.argmax(1), p2.argmax(1)\n",
    "    context_text = [[vocab.itos[word_idx.item()] for word_idx in context_idx] for context_idx in data.context_words[0]]\n",
    "    \n",
    "    exact_accuracy = [accuracy(context_text[i], \n",
    "                               p1[i].item(), p2[i].item(), \n",
    "                               data.start_idx[i].item(), data.end_idx[i].item(),\n",
    "                               method='exact_match') \n",
    "                      for i in range(data.batch_size)]\n",
    "    \n",
    "    f1_accuracy = [accuracy(context_text[i], \n",
    "                            p1[i].item(), p2[i].item(), \n",
    "                            data.start_idx[i].item(), data.end_idx[i].item(),\n",
    "                            method='f1') \n",
    "                   for i in range(data.batch_size)]\n",
    "    \n",
    "    return exact_accuracy, f1_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data, model, vocab):\n",
    "    model.eval()\n",
    "    index, exact_accurancy, f1_accuracy = [], [], []\n",
    "    for batch_data in iter(data):\n",
    "        p1, p2 = model(batch_data)\n",
    "        batch_exact_accuracy, batch_f1_accuracy = evaluate_batch_accuracy(batch_data, vocab, p1, p2)\n",
    "        index += batch_data.id\n",
    "        exact_accurancy += batch_exact_accuracy\n",
    "        f1_accuracy += batch_f1_accuracy\n",
    "        \n",
    "        \n",
    "    results = pd.DataFrame({'id': index, 'Exact': exact_accurancy, 'F1': f1_accuracy})\n",
    "    return results, results.groupby('id')['Exact'].max().mean(), results.groupby('id')['F1'].max().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss(data, model):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    examples_count = 0.0\n",
    "    for batch_data in iter(data):\n",
    "        examples_count += batch_data.batch_size\n",
    "        p1, p2 = model(batch_data)\n",
    "        batch_loss = criterion(p1, batch_data.start_idx) + criterion(p2, batch_data.end_idx)\n",
    "        total_loss += batch_loss.item()\n",
    "        \n",
    "        \n",
    "    return total_loss/examples_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, path, epochs=200, epochs_log=10, model_checkpoint=5, pretrained_model=None):\n",
    "    start_time = time.time()      \n",
    "    for epoch in range(epochs):\n",
    "        # SETTING MODEL IN TRAINING MODE\n",
    "        model.train()\n",
    "        \n",
    "        epoch_loss = 0\n",
    "        batch_num = 0.0\n",
    "        exmaples_count = 0.0\n",
    "        best_dev_acc_exact = -1.0\n",
    "        best_dev_acc_f1 = -1.0\n",
    "        \n",
    "        for train_data in iter(data_preprocessor.train_iter):\n",
    "            batch_num += 1.0\n",
    "            exmaples_count += train_data.batch_size\n",
    "            p1, p2 = model(train_data)\n",
    "            optimizer.zero_grad()\n",
    "            try:\n",
    "                batch_loss = criterion(p1, train_data.start_idx) + criterion(p2, train_data.end_idx)\n",
    "            except Exception as e:\n",
    "                print (e)\n",
    "                return (p1, p2, train_data)\n",
    "                \n",
    "            epoch_loss += batch_loss.item()\n",
    "            batch_loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            time_delta = datetime.timedelta(seconds=np.round(time.time() - start_time, 0))\n",
    "            sys.stdout.write(f'\\rEpoch:{epoch} | Batch:{batch_num} | Time Running: {time_delta}')\n",
    "            \n",
    "            \n",
    "        if epoch % epochs_log == 0:\n",
    "#             print (epoch_loss, exmaples_count)\n",
    "            triain_loss = epoch_loss/(exmaples_count)\n",
    "            dev_loss = evaluate_loss(data_preprocessor.dev_iter, model)\n",
    "            \n",
    "            _, train_accuracy_exact, train_accuracy_f1 = evaluate_accuracy(data_preprocessor.train_iter, \n",
    "                                                                        model, \n",
    "                                                                        data_preprocessor.WORDS.vocab)\n",
    "            _, dev_accuracy_exact, dev_accuracy_f1 = evaluate_accuracy(data_preprocessor.dev_iter, \n",
    "                                                                    model, \n",
    "                                                                    data_preprocessor.WORDS.vocab)\n",
    "            \n",
    "            print (f'\\nTrain Loss:{triain_loss:.4f} Train Acc Exact:{train_accuracy_exact:.4f} Train Acc F1:{train_accuracy_f1:.4f}')\n",
    "            print (f'Validation Loss :{dev_loss:.4f} Dev Acc Exact:{dev_accuracy_exact:.4f} Dev Acc F1:{dev_accuracy_f1:.4f}')\n",
    "            \n",
    "            print ('Test Prediction Results')\n",
    "            predict_context = \"He was speaking after figures showed that the country's economy shrank by 20.4% in April - the largest monthly contraction on record - as the country spent its first full month in lockdown.\"\n",
    "            predict_ques = \"By how much did the country's economy shrank\"\n",
    "            print (predition(predict_context, predict_ques, model, data_preprocessor))\n",
    "            \n",
    "            if dev_accuracy_f1 > best_dev_acc_f1:\n",
    "                best_dev_acc_f1 = dev_accuracy_f1\n",
    "                best_dev_acc_exact = dev_accuracy_exact\n",
    "                best_model = copy.deepcopy(model)\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': epoch_loss,\n",
    "                }, path + 'best_moodel.torch')\n",
    "            \n",
    "            \n",
    "        if epoch%model_checkpoint == 0:   \n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': epoch_loss,\n",
    "            }, path + 'model.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_data(context_tokenized, question_tokenized, model, preprocessor):\n",
    "    \n",
    "    longest_context_word = max([len(w) for w in context_tokenized])\n",
    "    longest_question_word = max([len(w) for w in question_tokenized])\n",
    "    \n",
    "    context_words = (torch.tensor([[preprocessor.WORDS.vocab[word.lower()] for word in context_tokenized]]),\n",
    "                     torch.tensor([len(context_tokenized)]))\n",
    "    \n",
    "    question_words = (torch.tensor([[preprocessor.WORDS.vocab[word.lower()] for word in question_tokenized]]),\n",
    "                     torch.tensor([len(question_tokenized)]))\n",
    "    \n",
    "    context_char = []\n",
    "    for word in context_tokenized:\n",
    "        _context_word = []\n",
    "        for c_index in range(longest_context_word):\n",
    "            if c_index < len(word):\n",
    "                _context_word.append(preprocessor.CHAR.vocab[word[c_index]])\n",
    "            else:\n",
    "                _context_word.append(preprocessor.CHAR.vocab['<pad>'])\n",
    "        context_char.append(_context_word)  \n",
    "    context_char = torch.tensor([context_char])\n",
    "    \n",
    "    question_char = []\n",
    "    for word in question_tokenized:\n",
    "        _question_word = []\n",
    "        for c_index in range(longest_question_word):\n",
    "            if c_index < len(word):\n",
    "                _question_word.append(preprocessor.CHAR.vocab[word[c_index]])\n",
    "            else:\n",
    "                _question_word.append(preprocessor.CHAR.vocab['<pad>'])\n",
    "        question_char.append(_question_word)\n",
    "    question_char = torch.tensor([question_char])\n",
    "    \n",
    "    predict_data.context_words = context_words\n",
    "    predict_data.question_words = question_words\n",
    "    predict_data.context_char = context_char\n",
    "    predict_data.question_char = question_char\n",
    "    predict_data.batch_size = 1\n",
    "    \n",
    "def predition(context, question, model, preprocessor):\n",
    "    model.eval()\n",
    "    context_tokenized = ptbtokenizer(context, context=True)\n",
    "    question_tokenized = ptbtokenizer(question)\n",
    "    \n",
    "    predict_data(context_tokenized, question_tokenized, model, preprocessor)\n",
    "    p1, p2 = model(predict_data)\n",
    "    \n",
    "    answer = \" \".join(context_tokenized[p1.argmax(1): p2.argmax(1)])\n",
    "    \n",
    "    return answer, p1.argmax(1), p2.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 | Batch:133.0 | Time Running: 9:40:32"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-84d0697257b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m           \u001b[0mepochs_log\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m           \u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m           pretrained_model=None)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-9e4f77428e4d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, path, epochs, epochs_log, model_checkpoint, pretrained_model)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/practice_projects/venv/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/practice_projects/venv/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "PATH = './model_checkpoints/'\n",
    "\n",
    "# Loading from Stored Path\n",
    "model = BidaF(data_preprocessor.WORDS, \n",
    "              data_preprocessor.CHAR,\n",
    "              char_embedding_size = 100,\n",
    "              char_conv_kernel_size = 5,\n",
    "              char_conv_channels_count = 100)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=0.5, rho=0.999)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if os.path.isfile(PATH + 'moodel.torch'):\n",
    "    checkpoint = torch.load(PATH + 'moodel.torch')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print ('Loaded Trained Model')\n",
    "    print (f'Trained for {epoch} Epochs, Achieved {loss} Training Loss')\n",
    "    \n",
    "_error = train(model=model, \n",
    "          optimizer=optimizer, \n",
    "          criterion=criterion, \n",
    "          path=PATH, \n",
    "          epochs=10, \n",
    "          epochs_log=1, \n",
    "          model_checkpoint=2, \n",
    "          pretrained_model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_p1, _p2, _data = _error[0], _error[1], _error[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102,\n",
       "        102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102,\n",
       "        102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 101, 101, 101, 101,\n",
       "        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "        101, 101, 101, 101, 101, 101, 101, 101])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_data.context_words[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 82,  57,  49,  27,  17,  85,  69,  94,  25,   9,  35,  61,  32,  14,\n",
       "         51,  17, 100,  96,  88,  11,  93,  54,  14, 102,  82,  14,  34,  99,\n",
       "          5,  38,  49,  88,  93,  62,  77,  46,  63,  14,  25,  92,   6,  31,\n",
       "         80,  34,   4,  88,   1,  12,  17,  69,  19,   2,  70,  23,  83,   8,\n",
       "         92,  31,  39,  17,  87,   7, 101,  90,  78,  97,   2,  49, 100, 100,\n",
       "         19,  91,  25,  37,  80,  26,  51,  33,   6,   3, 100,  62,  78,  78,\n",
       "         81,  41,   6,  50,  53, 100, 101,  66,  80,  90,  79,  93,  65,  69,\n",
       "         93,   8,  89,  45,   2,  86,  12,  41,  49,  65,  54,  56,  73,  70,\n",
       "         14,  25,  22,  94,  70,  22,  18,  19])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_data.end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 13,   0,  68,  99,  51,   3,  28,  60,  72,  21,  10, 101,  94, 100,\n",
       "         62,  98,   0,   1,  93,  97,  90,  47, 100,  20, 100,  50,  66,  98,\n",
       "         86,   0,  43,  15,  40,  40,   1, 101,  28,  84,   6, 101,  69,   0,\n",
       "         40,  14,  90, 101,  44,  95,  34,  89,  20,  37,  20,   6,  49,  89,\n",
       "         92, 101,  44,  56,  37,  52,  66,  86,   0, 101,  59,   1,  67,   0,\n",
       "          0,  97,   7,  12,  55,  20,   0,  20,  76,  98,  14,  77,  73,  83,\n",
       "         32,  89,  13,  31,  69,  22,  94,  31,   0,  67,  83,  78,  25,   0,\n",
       "          1,  31,  18,  82, 100,  14,   0,  93, 101,  37, 101,  88,  53,  61,\n",
       "         33,  49,   9,  59,  41,  44,  94,   0])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_p1.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 13,   0,  68,  99,  51,   3,  28,  60,  72,  21,  10, 101,  94, 100,\n",
       "         62,  98,   0,   1,  93,  97,  90,  47, 100,  20, 100,  50,  66,  98,\n",
       "         86,   0,  43,  15,  40,  40,   1, 101,  28,  84,   6, 101,  69,   0,\n",
       "         40,  14,  90, 101,  44,  95,  34,  89,  20,  37,  20,   6,  49,  89,\n",
       "         92, 101,  44,  56,  37,  52,  66,  86,   0, 101,  59,   1,  67,   0,\n",
       "          0,  97,   7,  12,  55,  20,   0,  20,  76,  98,  14,  77,  73,  83,\n",
       "         32,  89,  13,  31,  69,  22,  94,  31,   0,  67,  83,  78,  25,   0,\n",
       "          1,  31,  18,  82, 100,  14,   0,  93, 101,  37, 101,  88,  53,  61,\n",
       "         33,  49,   9,  59,  41,  44,  94,   0])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_p2.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"He was speaking after figures showed that the country 's economy shrank by 20 . 4\",\n",
       " tensor([0]),\n",
       " tensor([16]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_context = \"He was speaking after figures showed that the country's economy shrank by 20.4% in April - the largest monthly contraction on record - as the country spent its first full month in lockdown.\"\n",
    "predict_ques = \"By how much did the country's economy shrank\"\n",
    "\n",
    "predition(predict_context, predict_ques, model, data_preprocessor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
